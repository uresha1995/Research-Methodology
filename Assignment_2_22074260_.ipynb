{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEGRjx4gAgfAxnmTdGrmZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uresha1995/Research-Methodology/blob/main/Assignment_2_22074260_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentiment Analysis on the IMDb dataset**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "a1_RCvgucniU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pOvqSBc7rrr"
      },
      "outputs": [],
      "source": [
        "!pip install --no-cache-dir transformers==4.38.2 datasets==2.18.0 evaluate==0.4.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "import evaluate\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import random\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3rFk4gLz7ysG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download dataset from Hugging Face datasets\n",
        "#Dataset contains 50,000 movie reviews labelled as positive (1) or negative (0)\n",
        "\n",
        "dataset = load_dataset(\"imdb\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "qDn0SgyzQqXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print  random reviews\n",
        "#To understand the dataset content\n",
        "\n",
        "sample_texts = [dataset[\"train\"][i][\"text\"] for i in random.sample(range(25000), 5)]\n",
        "\n",
        "for i, text in enumerate(sample_texts):\n",
        "    print(f\"--- Sample {i+1} ---\\n{text[:500]}\\n\")"
      ],
      "metadata": {
        "id": "xUuQZPnLRH7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "6EdXnmPzQ03n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove empty and short reviews\n",
        "#less than 20 characters\n",
        "\n",
        "def rem_empty(example):\n",
        "    return len(example[\"text\"].strip()) > 20"
      ],
      "metadata": {
        "id": "_3k0M07WQ0gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove HTML break tags and replace with space\n",
        "\n",
        "def clean_text(example):\n",
        "    text = example[\"text\"]\n",
        "    text = re.sub(r\"<br\\s*/?>\", \" \", text)\n",
        "    example[\"text\"] = text.strip()\n",
        "    return example"
      ],
      "metadata": {
        "id": "T8Fv0W1aRlhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter out short reviews\n",
        "\n",
        "dataset[\"train\"] = dataset[\"train\"].filter(rem_empty)\n",
        "dataset[\"test\"] = dataset[\"test\"].filter(rem_empty)\n",
        "dataset = dataset.map(clean_text)"
      ],
      "metadata": {
        "id": "rYk5OoH2Q-d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization using BertTokenizerFast"
      ],
      "metadata": {
        "id": "HNiojL_RRwCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Making subset for training and testing\n",
        "#Shuffle and take small subset to train/test faster\n",
        "\n",
        "train_data = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "test_data = dataset[\"test\"].shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "id": "MkXVghEaSz6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define tokenization function\n",
        "#Load the BERT tokenizer\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )"
      ],
      "metadata": {
        "id": "I00So7m1R3yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply tokenization\n",
        "\n",
        "tokenized_train = small_train.map(tokenize_function, batched=True)\n",
        "tokenized_test = small_test.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "HYryccZS26tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to PyTorch tensor format\n",
        "#Make data compatible with DataLoader and training loop\n",
        "\n",
        "train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "metadata": {
        "id": "WXzp9LEGScVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create PyTorch DataLoaders for batching during training/testing\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=16)"
      ],
      "metadata": {
        "id": "Ot2vLeti5vza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load pre-trained BERT model for binary classification\n",
        "#Use GPU if available\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n"
      ],
      "metadata": {
        "id": "fZDM6zxSS-RP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer for training the model\n",
        "\n",
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "KkhOUDVnabvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "ZkimFV4SdlNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine-tune the BERT model for 2 epochs\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 2\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        batch['labels'] = batch.pop('label')  # Ensure label is correctly named\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1} - Training Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "id": "lQcATn8JpNGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "fBTmgy_pxBN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate model on the test dataset\n",
        "#Test accuracy and classification report\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        if 'label' in batch:\n",
        "            batch['labels'] = batch.pop('label')\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        all_preds.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"Negative\", \"Positive\"]))\n"
      ],
      "metadata": {
        "id": "cxRwreQeRIf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Compute the confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
        "\n",
        "#Display the matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
        "\n",
        "#Plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "disp.plot(cmap=\"Blues\", values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-84ptO_sTuIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#F1 score\n",
        "\n",
        "#Print F1-score\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "giBquI--uA8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample prediction"
      ],
      "metadata": {
        "id": "BPxdQhKtugIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict sentiment with confidence\n",
        "def predict_sentiment(text):\n",
        "\n",
        "    #Tokenize input and move to same device as model\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
        "\n",
        "    #Forward pass through the model\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    #Get predicted class and confidence\n",
        "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return \"Positive\" if predicted_class == 1 else \"Negative\"\n",
        "\n",
        "#Example predictions\n",
        "sample_texts = [\n",
        "    \"The movie was absolutely fantastic!\",\n",
        "    \"It was a boring and predictable film.\",\n",
        "    \"I don't know how to feel about it.\",\n",
        "    \"This is the best performance I've ever seen.\",\n",
        "    \"The film tried hard but didnâ€™t deliver much.\",\n",
        "    \"Honestly, I expected more from the director.\",\n",
        "    \"A masterpiece. Every scene was beautifully crafted\"\n",
        "]\n",
        "\n",
        "#Print result\n",
        "for text in sample_texts:\n",
        "    sentiment = predict_sentiment(text)\n",
        "    print(f\"Text: {text}\\nPredicted Sentiment: {sentiment}\\n\")"
      ],
      "metadata": {
        "id": "Ep_mLpxUue53"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}